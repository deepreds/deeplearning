{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#https://www.pyimagesearch.com/2019/05/20/transfer-learning-with-keras-and-deep-learning/\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # Set to -1 if CPU should be used CPU = -1 , GPU = 0\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "elif cpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        logical_cpus= tf.config.experimental.list_logical_devices('CPU')\n",
    "        print(len(cpus), \"Physical CPU,\", len(logical_cpus), \"Logical CPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import os\n",
    "\n",
    "# initialize the path to the *original* input directory of images\n",
    "ORIG_INPUT_DATASET = \"Food-5K.zip\"\n",
    "\n",
    "# initialize the base path to the *new* directory that will contain\n",
    "# our images after computing the training and testing split\n",
    "import tempfile\n",
    "TEMPDIR = tempfile.gettempdir()\n",
    "BASE_PATH = os.path.join(TEMPDIR, \"dataset.zip\")\n",
    "\n",
    "# define the names of the training, testing, and validation\n",
    "# directories\n",
    "TRAIN = \"training\"\n",
    "TEST = \"evaluation\"\n",
    "VAL = \"validation\"\n",
    "\n",
    "# initialize the list of class label names\n",
    "CLASSES = [\"non_food\", \"food\"]\n",
    "\n",
    "# set the batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# initialize the label encoder file path and the output directory to\n",
    "# where the extracted features (in CSV file format) will be stored\n",
    "LE_PATH = os.path.sep.join([TEMPDIR, \"le.cpickle\"])\n",
    "#BASE_CSV_PATH = \"output\"\n",
    "BASE_CSV_PATH = TEMPDIR\n",
    "\n",
    "# set the path to the serialized model after training\n",
    "MODEL_PATH = os.path.sep.join([TEMPDIR, \"model.cpickle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from imutils import paths\n",
    "import shutil\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing split images...\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import cv2\n",
    "zf = zipfile.ZipFile(ORIG_INPUT_DATASET)\n",
    "imagelist = zf.namelist()\n",
    "\n",
    "print(\"[INFO] processing split images...\")\n",
    "\n",
    "ozf = zipfile.ZipFile(BASE_PATH, 'w')\n",
    "\n",
    "# loop over the data splits\n",
    "for split in (TRAIN, TEST, VAL):\n",
    "\t# grab all image paths in the current split\n",
    "\t#print(\"[INFO] processing '{} split'...\".format(split))\n",
    "\t#p = os.path.sep.join([ORIG_INPUT_DATASET, split])\n",
    "\t#imagePaths = list(paths.list_images(p))\n",
    "\timagePaths = [ix for ix in imagelist if ix.startswith(split)]\n",
    "\n",
    "\t# loop over the image paths\n",
    "\tfor imagePath in imagePaths:\n",
    "\t\t# extract class label from the filename\n",
    "\t\t#filename = imagePath.split(os.path.sep)[-1]\n",
    "\t\tfilename = imagePath.split('/')[-1]\n",
    "\t\tlabel = CLASSES[int(filename.split(\"_\")[0])]\n",
    "\n",
    "\t\t# construct the path to the output directory\n",
    "\t\t#dirPath = os.path.sep.join([BASE_PATH, split, label])\n",
    "\t\tdirPath = '/'.join([split, label])\n",
    "\n",
    "\t\t# if the output directory does not exist, create it\n",
    "\t\t#if not os.path.exists(dirPath):\n",
    "\t\t#\tos.makedirs(dirPath)\n",
    "\n",
    "\t\t# construct the path to the output image file and copy it\n",
    "\t\t#p = os.path.sep.join([dirPath, filename])\n",
    "\t\t#shutil.copy2(imagePath, p)\n",
    "\t\t#image = cv2.imdecode(np.frombuffer(zf.read(imagePath), np.uint8), 1)\n",
    "\t\t#ozf.writestr(dirPath + '/' + filename, image, compress_type=zipfile.ZIP_STORED)\n",
    "\t\tozf.writestr(dirPath + '/' + filename, zf.read(imagePath), compress_type=zipfile.ZIP_STORED)\n",
    "zf.close()\n",
    "ozf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n"
     ]
    }
   ],
   "source": [
    "# load the VGG16 network and initialize the label encoder\n",
    "print(\"[INFO] loading network...\")\n",
    "model = VGG16(weights=\"imagenet\", include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing split images...\n",
      "['training/non_food/0_939.jpg', 'training/non_food/0_487.jpg', 'training/food/1_331.jpg', 'training/non_food/0_1376.jpg', 'training/food/1_347.jpg'] ['non_food', 'non_food', 'food', 'non_food', 'food']\n",
      "[INFO] processing batch 1/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 2/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 3/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 4/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 5/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 6/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 7/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 8/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 9/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 10/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 11/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 12/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 13/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 14/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 15/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 16/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 17/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 18/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 19/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 20/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 21/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 22/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 23/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 24/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 25/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 26/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 27/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 28/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 29/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 30/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 31/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 32/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 33/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 34/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 35/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 36/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 37/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 38/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 39/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 40/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 41/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 42/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 43/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 44/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 45/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 46/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 47/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 48/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 49/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 50/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 51/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 52/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 53/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 54/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 55/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 56/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 57/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 58/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 59/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 60/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 61/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 62/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 63/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 64/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 65/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 66/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 67/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 68/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 69/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 70/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 71/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 72/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 73/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 74/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 75/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 76/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 77/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 78/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 79/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 80/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 81/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 82/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 83/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 84/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 85/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 86/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 87/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 88/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 89/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 90/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 91/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 92/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 93/94\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 94/94\n",
      "(24, 7, 7, 512)\n",
      "['evaluation/non_food/0_329.jpg', 'evaluation/non_food/0_296.jpg', 'evaluation/non_food/0_205.jpg', 'evaluation/food/1_241.jpg', 'evaluation/food/1_229.jpg'] ['non_food', 'non_food', 'non_food', 'food', 'food']\n",
      "[INFO] processing batch 1/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 2/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 3/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 4/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 5/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 6/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 7/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 8/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 9/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 10/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 11/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 12/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 13/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 14/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 15/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 16/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 17/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 18/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 19/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 20/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 21/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 22/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 23/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 24/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 25/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 26/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 27/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 28/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 29/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 30/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 31/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 32/32\n",
      "(8, 7, 7, 512)\n",
      "['validation/food/1_33.jpg', 'validation/non_food/0_152.jpg', 'validation/non_food/0_201.jpg', 'validation/non_food/0_491.jpg', 'validation/food/1_96.jpg'] ['food', 'non_food', 'non_food', 'non_food', 'food']\n",
      "[INFO] processing batch 1/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 2/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 3/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 4/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 5/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 6/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 7/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 8/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 9/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 10/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 11/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 12/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 13/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 14/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 15/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 16/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 17/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 18/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 19/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 20/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 21/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 22/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 23/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 24/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 25/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 26/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 27/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 28/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 29/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 30/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 31/32\n",
      "(32, 7, 7, 512)\n",
      "[INFO] processing batch 32/32\n",
      "(8, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "zf = zipfile.ZipFile(BASE_PATH)\n",
    "imagelist = zf.namelist()\n",
    "\n",
    "print(\"[INFO] processing split images...\")\n",
    "\n",
    "le = None\n",
    "\n",
    "# loop over the data splits\n",
    "for split in (TRAIN, TEST, VAL):\n",
    "\t# grab all image paths in the current split\n",
    "\t#print(\"[INFO] processing '{} split'...\".format(split))\n",
    "\t#p = os.path.sep.join([BASE_PATH, split])\n",
    "\t#imagePaths = list(paths.list_images(p))\n",
    "\timagePaths = [ix for ix in imagelist if ix.startswith(split)]\n",
    "\n",
    "\t# randomly shuffle the image paths and then extract the class\n",
    "\t# labels from the file paths\n",
    "\trandom.shuffle(imagePaths)\n",
    "\t#labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
    "\tlabels = [p.split('/')[1] for p in imagePaths]\n",
    "\tprint(imagePaths[:5], labels[:5])\n",
    "\n",
    "\t# if the label encoder is None, create it\n",
    "\tif le is None:\n",
    "\t\tle = LabelEncoder()\n",
    "\t\tle.fit(labels)\n",
    "\n",
    "\t# open the output CSV file for writing\n",
    "\tcsvPath = os.path.sep.join([BASE_CSV_PATH,\"{}.csv\".format(split)])\n",
    "\tcsv = open(csvPath, \"w\")\n",
    "\n",
    "\t# loop over the images in batches\n",
    "\tfor (b, i) in enumerate(range(0, len(imagePaths), BATCH_SIZE)):\n",
    "\t\t# extract the batch of images and labels, then initialize the\n",
    "\t\t# list of actual images that will be passed through the network\n",
    "\t\t# for feature extraction\n",
    "\t\tprint(\"[INFO] processing batch {}/{}\".format(b + 1,int(np.ceil(len(imagePaths) / float(BATCH_SIZE)))))\n",
    "\t\tbatchPaths = imagePaths[i:i + BATCH_SIZE]\n",
    "\t\t#print(list(le.classes_), imagePaths[:5], labels[:5])\n",
    "\t\tbatchLabels = le.transform(labels[i:i + BATCH_SIZE])\n",
    "\t\tbatchImages = []\n",
    "\n",
    "\t\t# loop over the images and labels in the current batch\n",
    "\t\tfor imagePath in batchPaths:\n",
    "\t\t\t# load the input image using the Keras helper utility\n",
    "\t\t\t# while ensuring the image is resized to 224x224 pixels\n",
    "\t\t\t#image = load_img(imagePath, target_size=(224, 224))\n",
    "\t\t\t#image = img_to_array(image)\n",
    "\t\t\timage = cv2.imdecode(np.frombuffer(zf.read(imagePath), np.uint8), 1)\n",
    "\t\t\timage = cv2.resize(image, (224, 224))\n",
    "\n",
    "\t\t\t# preprocess the image by (1) expanding the dimensions and\n",
    "\t\t\t# (2) subtracting the mean RGB pixel intensity from the\n",
    "\t\t\t# ImageNet dataset\n",
    "\t\t\timage = np.expand_dims(image, axis=0)\n",
    "\t\t\timage = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "\t\t\t# add the image to the batch\n",
    "\t\t\tbatchImages.append(image)\n",
    "\n",
    "\t\t# pass the images through the network and use the outputs as\n",
    "\t\t# our actual features, then reshape the features into a\n",
    "\t\t# flattened volume\n",
    "\t\tbatchImages = np.vstack(batchImages)\n",
    "\t\tfeatures = model.predict(batchImages, batch_size=BATCH_SIZE)\n",
    "\t\tprint(features.shape)\n",
    "\t\tfeatures = features.reshape((features.shape[0], 7 * 7 * 512))\n",
    "\n",
    "\t\t# loop over the class labels and extracted features\n",
    "\t\tfor (label, vec) in zip(batchLabels, features):\n",
    "\t\t\t# construct a row that exists of the class label and\n",
    "\t\t\t# extracted features\n",
    "\t\t\tvec = \",\".join([str(v) for v in vec])\n",
    "\t\t\tcsv.write(\"{},{}\\n\".format(label, vec))\n",
    "\n",
    "\t# close the CSV file\n",
    "\tcsv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the label encoder to disk\n",
    "f = open(LE_PATH, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_split(splitPath):\n",
    "\t# initialize the data and labels\n",
    "\tdata = []\n",
    "\tlabels = []\n",
    "\n",
    "\t# loop over the rows in the data split file\n",
    "\tfor row in open(splitPath):\n",
    "\t\t# extract the class label and features from the row\n",
    "\t\trow = row.strip().split(\",\")\n",
    "\t\tlabel = row[0]\n",
    "\t\tfeatures = np.array(row[1:], dtype=\"float\")\n",
    "\n",
    "\t\t# update the data and label lists\n",
    "\t\tdata.append(features)\n",
    "\t\tlabels.append(label)\n",
    "\n",
    "\t# convert the data and labels to NumPy arrays\n",
    "\tdata = np.array(data)\n",
    "\tlabels = np.array(labels)\n",
    "\n",
    "\t# return a tuple of the data and labels\n",
    "\treturn (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive the paths to the training and testing CSV files\n",
    "trainingPath = os.path.sep.join([BASE_CSV_PATH,\"{}.csv\".format(TRAIN)])\n",
    "testingPath = os.path.sep.join([BASE_CSV_PATH,\"{}.csv\".format(TEST)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading data...\n"
     ]
    }
   ],
   "source": [
    "# load the data from disk\n",
    "print(\"[INFO] loading data...\")\n",
    "(trainX, trainY) = load_data_split(trainingPath)\n",
    "(testX, testY) = load_data_split(testingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the label encoder from disk\n",
    "le = pickle.loads(open(LE_PATH, \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "model = LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\", max_iter=1000)\n",
    "model.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        food       0.98      0.97      0.97       500\n",
      "    non_food       0.97      0.98      0.98       500\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.98      0.97      0.97      1000\n",
      "weighted avg       0.98      0.97      0.97      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "print(\"[INFO] evaluating...\")\n",
    "preds = model.predict(testX)\n",
    "print(classification_report(testY, preds, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving model...\n"
     ]
    }
   ],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] saving model...\")\n",
    "f = open(MODEL_PATH, \"wb\")\n",
    "f.write(pickle.dumps(model))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
