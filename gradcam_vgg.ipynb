{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "\n",
    "#from tensorflow.keras import backend as K\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"Function returning keras model instance.\n",
    "    \n",
    "    Model can be\n",
    "     - Trained here\n",
    "     - Loaded with load_model\n",
    "     - Loaded from keras.applications\n",
    "    \"\"\"\n",
    "    return VGG16(include_top=True, weights='imagenet')\n",
    "\n",
    "H, W = 224, 224 # Input shape, defined by the model (model.input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, preprocess=True):\n",
    "    \"\"\"Load and preprocess image.\"\"\"\n",
    "    x = image.load_img(path, target_size=(H, W))\n",
    "    if preprocess:\n",
    "        x = image.img_to_array(x)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    \"\"\"Same normalization as in:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
    "    \"\"\"\n",
    "    x = x.copy()\n",
    "    if np.ndim(x) > 3:\n",
    "        x = np.squeeze(x)\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\"Utility function to normalize a tensor by its L2 norm\"\"\"\n",
    "    return (x + 1e-10) / (K.sqrt(K.mean(K.square(x))) + 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_guided_model():\n",
    "    \"\"\"Function returning modified model.\n",
    "    \n",
    "    Changes gradient function for all ReLu activations\n",
    "    according to Guided Backpropagation.\n",
    "    \"\"\"\n",
    "    if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n",
    "        @ops.RegisterGradient(\"GuidedBackProp\")\n",
    "        def _GuidedBackProp(op, grad):\n",
    "            dtype = op.inputs[0].dtype\n",
    "            return grad * tf.cast(grad > 0., dtype) * \\\n",
    "                   tf.cast(op.inputs[0] > 0., dtype)\n",
    "\n",
    "    #g = tf.get_default_graph()\n",
    "    g = tf.compat.v1.get_default_graph()\n",
    "    with g.gradient_override_map({'Relu': 'GuidedBackProp'}):\n",
    "        new_model = build_model()\n",
    "    return new_model\n",
    "\n",
    "\n",
    "def guided_backprop(input_model, images, layer_name):\n",
    "    \"\"\"Guided Backpropagation method for visualizing input saliency.\"\"\"\n",
    "    input_imgs = input_model.input\n",
    "    layer_output = input_model.get_layer(layer_name).output\n",
    "    grads = K.gradients(layer_output, input_imgs)[0]\n",
    "    backprop_fn = K.function([input_imgs, K.learning_phase()], [grads])\n",
    "    grads_val = backprop_fn([images, 0])[0]\n",
    "    return grads_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam(input_model, image, cls, layer_name):\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    y_c = input_model.output[0, cls]\n",
    "    conv_output = input_model.get_layer(layer_name).output\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "    # Normalize if necessary\n",
    "    # grads = normalize(grads)\n",
    "    gradient_function = K.function([input_model.input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "\n",
    "    # Process CAM\n",
    "    cam = cv2.resize(cam, (W, H), cv2.INTER_LINEAR)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    return cam\n",
    "\n",
    "def grad_cam_batch(input_model, images, classes, layer_name):\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\n",
    "    Same as grad_cam but processes multiple images in one run.\"\"\"\n",
    "    loss = tf.gather_nd(input_model.output, np.dstack([range(images.shape[0]), classes])[0])\n",
    "    layer_output = input_model.get_layer(layer_name).output\n",
    "    grads = K.gradients(loss, layer_output)[0]\n",
    "    gradient_fn = K.function([input_model.input, K.learning_phase()], [layer_output, grads])\n",
    "\n",
    "    conv_output, grads_val = gradient_fn([images, 0])    \n",
    "    weights = np.mean(grads_val, axis=(1, 2))\n",
    "    cams = np.einsum('ijkl,il->ijk', conv_output, weights)\n",
    "    \n",
    "    # Process CAMs\n",
    "    new_cams = np.empty((images.shape[0], H, W))\n",
    "    for i in range(new_cams.shape[0]):\n",
    "        cam_i = cams[i] - cams[i].mean()\n",
    "        cam_i = (cam_i + 1e-10) / (np.linalg.norm(cam_i, 2) + 1e-10)\n",
    "        new_cams[i] = cv2.resize(cam_i, (W, H), cv2.INTER_LINEAR)\n",
    "        new_cams[i] = np.maximum(new_cams[i], 0)\n",
    "        new_cams[i] = new_cams[i] / new_cams[i].max()\n",
    "    \n",
    "    return new_cams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency(model, guided_model, img_path, layer_name='block5_conv3', cls=-1, visualize=True, save=True):\n",
    "    \"\"\"Compute saliency using all three approaches.\n",
    "        -layer_name: layer to compute gradients;\n",
    "        -cls: class number to localize (-1 for most probable class).\n",
    "    \"\"\"\n",
    "    preprocessed_input = load_image(img_path)\n",
    "\n",
    "    predictions = model.predict(preprocessed_input)\n",
    "    top_n = 5\n",
    "    top = decode_predictions(predictions, top=top_n)[0]\n",
    "    classes = np.argsort(predictions[0])[-top_n:][::-1]\n",
    "    print('Model prediction:')\n",
    "    for c, p in zip(classes, top):\n",
    "        print('\\t{:15s}\\t({})\\twith probability {:.3f}'.format(p[1], c, p[2]))\n",
    "    if cls == -1:\n",
    "        cls = np.argmax(predictions)\n",
    "    class_name = decode_predictions(np.eye(1, 1000, cls))[0][0][1]\n",
    "    print(\"Explanation for '{}'\".format(class_name))\n",
    "    \n",
    "    gradcam = grad_cam(model, preprocessed_input, cls, layer_name)\n",
    "    gb = guided_backprop(guided_model, preprocessed_input, layer_name)\n",
    "    guided_gradcam = gb * gradcam[..., np.newaxis]\n",
    "\n",
    "    if save:\n",
    "        jetcam = cv2.applyColorMap(np.uint8(255 * gradcam), cv2.COLORMAP_JET)\n",
    "        jetcam = (np.float32(jetcam) + load_image(img_path, preprocess=False)) / 2\n",
    "        cv2.imwrite('gradcam.jpg', np.uint8(jetcam))\n",
    "        cv2.imwrite('guided_backprop.jpg', deprocess_image(gb[0]))\n",
    "        cv2.imwrite('guided_gradcam.jpg', deprocess_image(guided_gradcam[0]))\n",
    "    \n",
    "    if visualize:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.subplot(131)\n",
    "        plt.title('GradCAM')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(load_image(img_path, preprocess=False))\n",
    "        plt.imshow(gradcam, cmap='jet', alpha=0.5)\n",
    "\n",
    "        plt.subplot(132)\n",
    "        plt.title('Guided Backprop')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(np.flip(deprocess_image(gb[0]), -1))\n",
    "        \n",
    "        plt.subplot(133)\n",
    "        plt.title('Guided GradCAM')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(np.flip(deprocess_image(guided_gradcam[0]), -1))\n",
    "        plt.show()\n",
    "        \n",
    "    return gradcam, gb, guided_gradcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "guided_model = build_guided_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction:\n",
      "\tbucket         \t(463)\twith probability 0.005\n",
      "\tcowboy_hat     \t(515)\twith probability 0.005\n",
      "\twater_bottle   \t(898)\twith probability 0.004\n",
      "\ttub            \t(876)\twith probability 0.004\n",
      "\twater_jug      \t(899)\twith probability 0.004\n",
      "Explanation for 'bucket'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d67ca1a21e86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m gradcam, gb, guided_gradcam = compute_saliency(model, guided_model, 'cat_dog.png', layer_name='block5_conv3', \n\u001b[0m\u001b[0;32m      2\u001b[0m                                                cls=-1, visualize=True, save=True)\n\u001b[0;32m      3\u001b[0m gradcam, gb, guided_gradcam = compute_saliency(model, guided_model, 'cat_dog.png', layer_name='block5_conv3',\n\u001b[0;32m      4\u001b[0m                                                cls=282, visualize=True, save=False)\n",
      "\u001b[1;32m<ipython-input-23-bcf6380b9f6f>\u001b[0m in \u001b[0;36mcompute_saliency\u001b[1;34m(model, guided_model, img_path, layer_name, cls, visualize, save)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Explanation for '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mgradcam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessed_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mguided_backprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mguided_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessed_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mguided_gradcam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgb\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgradcam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-576d9eaacc36>\u001b[0m in \u001b[0;36mgrad_cam\u001b[1;34m(input_model, image, cls, layer_name)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mconv_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Normalize if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# grads = normalize(grads)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(loss, variables)\u001b[0m\n\u001b[0;32m   3966\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3967\u001b[0m   \"\"\"\n\u001b[1;32m-> 3968\u001b[1;33m   return gradients_module.gradients(\n\u001b[0m\u001b[0;32m   3969\u001b[0m       loss, variables, colocate_gradients_with_ops=True)\n\u001b[0;32m   3970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    167\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m     return gradients_util._GradientsHelper(\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    489\u001b[0m   \u001b[1;34m\"\"\"Implementation of gradients().\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m     raise RuntimeError(\"tf.gradients is not supported when eager execution \"\n\u001b[0m\u001b[0;32m    492\u001b[0m                        \"is enabled. Use tf.GradientTape instead.\")\n\u001b[0;32m    493\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msrc_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
     ]
    }
   ],
   "source": [
    "gradcam, gb, guided_gradcam = compute_saliency(model, guided_model, 'cat_dog.png', layer_name='block5_conv3', \n",
    "                                               cls=-1, visualize=True, save=True)\n",
    "gradcam, gb, guided_gradcam = compute_saliency(model, guided_model, 'cat_dog.png', layer_name='block5_conv3',\n",
    "                                               cls=282, visualize=True, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating explanations for many images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all images from the folder into one array X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'dogs_and_cats'\n",
    "files = os.listdir(dir_path)\n",
    "N = len(files)\n",
    "\n",
    "X = np.empty((N, H, W, 3))\n",
    "for i, file in enumerate(files):\n",
    "    x = image.load_img(dir_path + file, target_size=(H, W))\n",
    "    X[i] = image.img_to_array(x)\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and save GradCAM saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set classes for explanations as most probable class for each image.\n",
    "top = np.argmax(model.predict(X), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam = np.empty((X.shape[:-1]))\n",
    "batch_size = 32\n",
    "for i in range((N + batch_size - 1) // batch_size):\n",
    "    start = i * batch_size\n",
    "    end = min((i+1) * batch_size, N)\n",
    "    gradcam[start:end] = grad_cam_batch(model, X[start:end], top[start:end], 'block5_conv3')\n",
    "    \n",
    "gradcam.tofile('gradcam.npy')\n",
    "\n",
    "i = 63\n",
    "plt.title(decode_predictions(np.eye(1, 1000, top[i]), 1)[0][0][1])\n",
    "plt.imshow(np.flip(deprocess_image(X[i]), -1))\n",
    "plt.imshow(gradcam[i], alpha=0.3, cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and save Guided Backpropagation saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbp = np.empty((X.shape))\n",
    "batch_size = 32\n",
    "for i in range((N + batch_size - 1) // batch_size):\n",
    "    start = i * batch_size\n",
    "    end = min((i+1) * batch_size, N)\n",
    "    gbp[start:end] = guided_backprop(guided_model, X[start:end], 'block5_conv3')\n",
    "    \n",
    "gbp.tofile('guided_backprop.npy')\n",
    "\n",
    "i = 63\n",
    "plt.title(decode_predictions(np.eye(1, 1000, top[i]), 1)[0][0][1])\n",
    "plt.imshow(np.flip(deprocess_image(gbp[i]), -1), cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and save Guided GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guided_gradcam = gbp * gradcam[..., np.newaxis]\n",
    "guided_gradcam.tofile('guided_gradcam.npy')\n",
    "\n",
    "i = 63\n",
    "plt.title(decode_predictions(np.eye(1, 1000, top[i]), 1)[0][0][1])\n",
    "plt.imshow(np.flip(deprocess_image(guided_gradcam[i]), -1), alpha=0.5, cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
